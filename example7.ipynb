{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"Ankita802/llm\"\n",
    "dataset = load_dataset(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------\n",
      "Example  1\n",
      "---------------------------------------------------------------------------------------------------\n",
      "INPUT QUERY:\n",
      "As a Data Consuming User, I want to see textual descriptions that accompany embedded visualisations, So that I can more easily understand what I am viewing.\t\n",
      "\n",
      "ANSWER:\n",
      "As a Data Consuming User, I seek textual descriptions accompanying embedded visualizations to enhance my understanding of the content. These descriptions provide valuable context and explanations that aid in comprehending the data presented, ensuring clarity and facilitating informed interpretation of the visual information.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Example  2\n",
      "---------------------------------------------------------------------------------------------------\n",
      "INPUT QUERY:\n",
      "As a CONNECT system administrator, I want documentation on PKI in CONNECT so that I have a reference for certificate setup and troubleshooting\t\n",
      "\n",
      "ANSWER:\n",
      "\n",
      "To create documentation on PKI in CONNECT for system administrators:\n",
      "\n",
      "Provide an overview of PKI and its importance in CONNECT.\n",
      "Outline the process of certificate setup, including generating, obtaining, and installing certificates.\n",
      "Detail the configuration steps for different components of CONNECT, such as Apache CXF, Tomcat, or other relevant services, to use certificates.\n",
      "Include troubleshooting guidelines for common PKI-related issues, such as certificate expiration, revocation, or mismatch errors.\n",
      "Provide examples and best practices for managing certificates securely within CONNECT.\n",
      "Include references to relevant standards or documentation for further reading.\n",
      "Ensure the documentation is well-organized, easily accessible, and regularly updated to reflect any changes or updates in PKI practices within CONNECT.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "example_indices = [10, 200]\n",
    "\n",
    "dash_line = '-'.join('' for x in range(100))\n",
    "\n",
    "for i, index in enumerate(example_indices):\n",
    "    print(dash_line)\n",
    "    print('Example ', i + 1)\n",
    "    print(dash_line)\n",
    "    print('INPUT QUERY:')\n",
    "    print(dataset['test'][index]['input'])\n",
    "    # print(dash_line)\n",
    "    print('ANSWER:')\n",
    "    print(dataset['test'][index]['result'])\n",
    "    print(dash_line)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, BertModel\n",
    "\n",
    "model_name =  \"google-bert/bert-base-uncased\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = BertModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[  101, 13366,  2177,  3762,  1006,  2969,  1010,  1008,  8902,  2015,\n",
      "          1007,  1024,  1046,  2290,  2094,  1027,  2969,  1012,  1035, 26219,\n",
      "          2546,  1012,  2177,  3762,  1006,  2969,  1012,  1035, 29175, 27896,\n",
      "          1006,  1008,  8902,  2015,  1007,  1007,  2013,  1052,  7274, 14432,\n",
      "          1012, 29296,  1012,  2177, 12324, 15131,  2850,  2696,  2709, 15131,\n",
      "          2850,  2696,  1006,  1046,  2290,  2094,  1010,  2969,  1007,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "def groupby ( self, * cols ) : jgd = self. _ jdf. groupby ( self. _ jcols ( * cols ) ) from pyspark. sql. group import groupeddata return groupeddata ( jgd, self )\n"
     ]
    }
   ],
   "source": [
    "sentence = \"def groupBy(self, *cols): jgd = self._jdf.groupBy(self._jcols(*cols)) from pyspark.sql.group import GroupedData return GroupedData(jgd, self) \"\n",
    "\n",
    "inputs = tokenizer(sentence, return_tensors=\"pt\")\n",
    "print(inputs)\n",
    "decoded_sentence = tokenizer.decode(\n",
    "            inputs['input_ids'][0],\n",
    "            skip_special_tokens=True)\n",
    "print(decoded_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "without prompt engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------\n",
      "Example  1\n",
      "---------------------------------------------------------------------------------------------------\n",
      "INPUT PROMPT:\n",
      "As a user, I want to have access to the content files for an object. \n",
      "\n",
      "ANSWER FROM CSV:\n",
      "As a user, I require access to the content files associated with an object. This feature will enable me to retrieve and utilize the actual content of the object, facilitating tasks such as viewing, editing, or sharing files within the system.\n",
      "\n",
      "MODEL GENERATION - WITHOUT PROMPT ENGINEERING:\n",
      "as a user, i want to have access to the content files for an object.\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Example  2\n",
      "---------------------------------------------------------------------------------------------------\n",
      "INPUT PROMPT:\n",
      "As a CONNECT tester, I would like to have a thorough set of regression tests for Document Retrieve, so that I can have proper test coverage\t\n",
      "\n",
      "ANSWER FROM CSV:\n",
      "To establish a comprehensive set of regression tests for Document Retrieve as a CONNECT tester:\n",
      "\n",
      "Analyze the Document Retrieve feature to understand its functionalities, inputs, and outputs.\n",
      "Collaborate with stakeholders to identify use cases, requirements, and expected behaviors.\n",
      "Develop a test plan that covers various scenarios, including:\n",
      "Retrieving documents by different criteria (e.g., patient ID, document ID, document type)\n",
      "Testing document retrieval in different formats (e.g., PDF, XML)\n",
      "Validating document retrieval responses against expected content and metadata\n",
      "Testing error handling and boundary cases (e.g., invalid document IDs, timeouts)\n",
      "Implement automation where feasible to streamline execution and improve efficiency.\n",
      "Execute the regression test suite regularly during the development lifecycle and before each release to ensure Document Retrieve functionality remains intact.\n",
      "Document test results, including any issues encountered during regression testing, for tracking and resolution.\n",
      "Continuously update and expand the regression test suite as new features are added or existing functionality evolves.\n",
      "Collaborate closely with developers and other team members to address any identified issues and ensure the quality of Document Retrieve functionality.\n",
      "\n",
      "MODEL GENERATION - WITHOUT PROMPT ENGINEERING:\n",
      "as a connect tester, i would like to have a thorough set of regression tests for document retrieve, so that i can have proper test coverage\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, index in enumerate(example_indices):\n",
    "    input_query  = dataset['train'][index]['input']\n",
    "    result = dataset['train'][index]['result']\n",
    "\n",
    "    inputs = tokenizer(input_query, return_tensors='pt')\n",
    "\n",
    "    decoded_input = tokenizer.decode(\n",
    "            inputs['input_ids'][0],\n",
    "            skip_special_tokens=True)\n",
    "\n",
    "    print(dash_line)\n",
    "    print('Example ', i + 1)\n",
    "    print(dash_line)\n",
    "    print(f'INPUT PROMPT:\\n{input_query}')\n",
    "    # print(dash_line)\n",
    "    print(f'ANSWER FROM CSV:\\n{result}')\n",
    "    print()\n",
    "    # print(dash_line)\n",
    "    print(f'MODEL GENERATION - WITHOUT PROMPT ENGINEERING:\\n{decoded_input}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "without prompt_engineering it will learn only few content from dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ZERO SHOT inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------\n",
      "Example  1\n",
      "---------------------------------------------------------------------------------------------------\n",
      "INPUT PROMPT:\n",
      "As a user, I want to have access to the content files for an object. \n",
      "\n",
      "ANSWER FROM CSV:\n",
      "As a user, I require access to the content files associated with an object. This feature will enable me to retrieve and utilize the actual content of the object, facilitating tasks such as viewing, editing, or sharing files within the system.\n",
      "\n",
      "MODEL GENERATION - WITH ONE SHOT LEARNING:\n",
      "providing the description as a user, i want to have access to the content files for an object.\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Example  2\n",
      "---------------------------------------------------------------------------------------------------\n",
      "INPUT PROMPT:\n",
      "As a CONNECT tester, I would like to have a thorough set of regression tests for Document Retrieve, so that I can have proper test coverage\t\n",
      "\n",
      "ANSWER FROM CSV:\n",
      "To establish a comprehensive set of regression tests for Document Retrieve as a CONNECT tester:\n",
      "\n",
      "Analyze the Document Retrieve feature to understand its functionalities, inputs, and outputs.\n",
      "Collaborate with stakeholders to identify use cases, requirements, and expected behaviors.\n",
      "Develop a test plan that covers various scenarios, including:\n",
      "Retrieving documents by different criteria (e.g., patient ID, document ID, document type)\n",
      "Testing document retrieval in different formats (e.g., PDF, XML)\n",
      "Validating document retrieval responses against expected content and metadata\n",
      "Testing error handling and boundary cases (e.g., invalid document IDs, timeouts)\n",
      "Implement automation where feasible to streamline execution and improve efficiency.\n",
      "Execute the regression test suite regularly during the development lifecycle and before each release to ensure Document Retrieve functionality remains intact.\n",
      "Document test results, including any issues encountered during regression testing, for tracking and resolution.\n",
      "Continuously update and expand the regression test suite as new features are added or existing functionality evolves.\n",
      "Collaborate closely with developers and other team members to address any identified issues and ensure the quality of Document Retrieve functionality.\n",
      "\n",
      "MODEL GENERATION - WITH ONE SHOT LEARNING:\n",
      "providing the description as a connect tester, i would like to have a thorough set of regression tests for document retrieve, so that i can have proper test coverage\n",
      "\n"
     ]
    }
   ],
   "source": [
    "example_indices = [10, 200]\n",
    "\n",
    "for i, index in enumerate(example_indices):\n",
    "    input_query = dataset['train'][index]['input']\n",
    "    result = dataset['train'][index]['result']\n",
    "\n",
    "    prompt_template = f\"\"\"\n",
    "   \n",
    "Providing the description {input_query}\n",
    "   \n",
    "   \"\"\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
    "\n",
    "\n",
    "    inputs = tokenizer(prompt_template, return_tensors='pt')\n",
    "\n",
    "    decoded_input = tokenizer.decode(\n",
    "            inputs['input_ids'][0],\n",
    "            skip_special_tokens=True)\n",
    "\n",
    "    print(dash_line)\n",
    "    print('Example ', i + 1)\n",
    "    print(dash_line)\n",
    "    print(f'INPUT PROMPT:\\n{input_query}')\n",
    "    # print(dash_line)\n",
    "    print(f'ANSWER FROM CSV:\\n{result}')\n",
    "    print()\n",
    "    # print(dash_line)\n",
    "    print(f'MODEL GENERATION - WITH ONE SHOT LEARNING:\\n{decoded_input}\\n')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ONE-SHOT Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prompt(example_indices_full, example_index_to_summarize):\n",
    "    prompt = ''\n",
    "    for index in example_indices_full:\n",
    "        input_query = dataset['train'][index]['input']\n",
    "        result = dataset['train'][index]['result']\n",
    "\n",
    "        # The stop sequence '{summary}\\n\\n\\n' is important for FLAN-T5. Other models may have their own preferred stop sequence.\n",
    "        prompt += f\"\"\" Providing the input query {input_query} Describing the input query {result} \"\"\"\n",
    "\n",
    "        dialogue = dataset['train'][example_index_to_summarize]['result']\n",
    "\n",
    "\n",
    "        prompt += f\"\"\" Providing the input query {input_query} Describing the input query {result} \"\"\"\n",
    "\n",
    "#     prompt += f\"\"\"\n",
    "# Dialogue:\n",
    "\n",
    "# {dialogue}\n",
    "\n",
    "# What was going on?\n",
    "# \"\"\"\n",
    "\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Providing the input query As an Archivist, I want to assign Location information to a Container.\n",
      " Describing the input query To assign Location information to a Container as an Archivist, you can follow these steps:\n",
      "\n",
      "1. Determine the physical location where the Container will be stored. This could be a specific shelf, room, or storage area within your archival facility.\n",
      "\n",
      "2. Create a unique identifier for the location, such as a shelf number or storage area code, to easily reference the Container's placement.\n",
      "\n",
      "3. Use a standardized system for recording the location information, such as a database or inventory management software, to ensure consistency and accuracy.\n",
      "\n",
      "4. Label the Container with its assigned location information, using clear and durable labeling materials to prevent confusion or misplacement.\n",
      "\n",
      "5. Update any relevant finding aids or catalog records to reflect the assigned location, making it easy for other archivists or researchers to locate the Container when needed.\n",
      "\n",
      "By following these steps, you can effectively assign location information to a Container as an Archivist, ensuring that it is properly stored and easily accessible for future use.  Providing the input query As an Archivist, I want to assign Location information to a Container.\n",
      " Describing the input query To assign Location information to a Container as an Archivist, you can follow these steps:\n",
      "\n",
      "1. Determine the physical location where the Container will be stored. This could be a specific shelf, room, or storage area within your archival facility.\n",
      "\n",
      "2. Create a unique identifier for the location, such as a shelf number or storage area code, to easily reference the Container's placement.\n",
      "\n",
      "3. Use a standardized system for recording the location information, such as a database or inventory management software, to ensure consistency and accuracy.\n",
      "\n",
      "4. Label the Container with its assigned location information, using clear and durable labeling materials to prevent confusion or misplacement.\n",
      "\n",
      "5. Update any relevant finding aids or catalog records to reflect the assigned location, making it easy for other archivists or researchers to locate the Container when needed.\n",
      "\n",
      "By following these steps, you can effectively assign location information to a Container as an Archivist, ensuring that it is properly stored and easily accessible for future use. \n"
     ]
    }
   ],
   "source": [
    "example_indices_full = [40]\n",
    "example_index_to_summarize = 200\n",
    "\n",
    "one_shot_prompt = make_prompt(example_indices_full, example_index_to_summarize)\n",
    "\n",
    "print(one_shot_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------\n",
      "Example  2\n",
      "---------------------------------------------------------------------------------------------------\n",
      "INPUT PROMPT:\n",
      "As a CONNECT tester, I would like to have a thorough set of regression tests for Document Retrieve, so that I can have proper test coverage\t\n",
      "\n",
      "ANSWER FROM CSV:\n",
      "To establish a comprehensive set of regression tests for Document Retrieve as a CONNECT tester:\n",
      "\n",
      "Analyze the Document Retrieve feature to understand its functionalities, inputs, and outputs.\n",
      "Collaborate with stakeholders to identify use cases, requirements, and expected behaviors.\n",
      "Develop a test plan that covers various scenarios, including:\n",
      "Retrieving documents by different criteria (e.g., patient ID, document ID, document type)\n",
      "Testing document retrieval in different formats (e.g., PDF, XML)\n",
      "Validating document retrieval responses against expected content and metadata\n",
      "Testing error handling and boundary cases (e.g., invalid document IDs, timeouts)\n",
      "Implement automation where feasible to streamline execution and improve efficiency.\n",
      "Execute the regression test suite regularly during the development lifecycle and before each release to ensure Document Retrieve functionality remains intact.\n",
      "Document test results, including any issues encountered during regression testing, for tracking and resolution.\n",
      "Continuously update and expand the regression test suite as new features are added or existing functionality evolves.\n",
      "Collaborate closely with developers and other team members to address any identified issues and ensure the quality of Document Retrieve functionality.\n",
      "\n",
      "MODEL GENERATION - WITH ONE SHOT LEARNING:\n",
      "providing the input query as an archivist, i want to assign location information to a container. describing the input query to assign location information to a container as an archivist, you can follow these steps : 1. determine the physical location where the container will be stored. this could be a specific shelf, room, or storage area within your archival facility. 2. create a unique identifier for the location, such as a shelf number or storage area code, to easily reference the container's placement. 3. use a standardized system for recording the location information, such as a database or inventory management software, to ensure consistency and accuracy. 4. label the container with its assigned location information, using clear and durable labeling materials to prevent confusion or misplacement. 5. update any relevant finding aids or catalog records to reflect the assigned location, making it easy for other archivists or researchers to locate the container when needed. by following these steps, you can effectively assign location information to a container as an archivist, ensuring that it is properly stored and easily accessible for future use. providing the input query as an archivist, i want to assign location information to a container. describing the input query to assign location information to a container as an archivist, you can follow these steps : 1. determine the physical location where the container will be stored. this could be a specific shelf, room, or storage area within your archival facility. 2. create a unique identifier for the location, such as a shelf number or storage area code, to easily reference the container's placement. 3. use a standardized system for recording the location information, such as a database or inventory management software, to ensure consistency and accuracy. 4. label the container with its assigned location information, using clear and durable labeling materials to prevent confusion or misplacement. 5. update any relevant finding aids or catalog records to reflect the assigned location, making it easy for other archivists or researchers to locate the container when needed. by following these steps, you can effectively assign location information to a container as an archivist, ensuring that it is properly stored and easily accessible for future use.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "result = dataset['train'][example_index_to_summarize]['result']\n",
    "\n",
    "inputs = tokenizer(one_shot_prompt, return_tensors='pt')\n",
    "\n",
    "decoded_input = tokenizer.decode(\n",
    "            inputs['input_ids'][0],\n",
    "            skip_special_tokens=True)\n",
    "\n",
    "print(dash_line)\n",
    "print('Example ', i + 1)\n",
    "print(dash_line)\n",
    "print(f'INPUT PROMPT:\\n{input_query}')\n",
    "    # print(dash_line)\n",
    "print(f'ANSWER FROM CSV:\\n{result}')\n",
    "print()\n",
    "    # print(dash_line)\n",
    "print(f'MODEL GENERATION - WITH ONE SHOT LEARNING:\\n{decoded_input}\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Few shot inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Providing the input query As an Archivist, I want to assign Location information to a Container.\n",
      " Describing the input query To assign Location information to a Container as an Archivist, you can follow these steps:\n",
      "\n",
      "1. Determine the physical location where the Container will be stored. This could be a specific shelf, room, or storage area within your archival facility.\n",
      "\n",
      "2. Create a unique identifier for the location, such as a shelf number or storage area code, to easily reference the Container's placement.\n",
      "\n",
      "3. Use a standardized system for recording the location information, such as a database or inventory management software, to ensure consistency and accuracy.\n",
      "\n",
      "4. Label the Container with its assigned location information, using clear and durable labeling materials to prevent confusion or misplacement.\n",
      "\n",
      "5. Update any relevant finding aids or catalog records to reflect the assigned location, making it easy for other archivists or researchers to locate the Container when needed.\n",
      "\n",
      "By following these steps, you can effectively assign location information to a Container as an Archivist, ensuring that it is properly stored and easily accessible for future use.  Providing the input query As an Archivist, I want to assign Location information to a Container.\n",
      " Describing the input query To assign Location information to a Container as an Archivist, you can follow these steps:\n",
      "\n",
      "1. Determine the physical location where the Container will be stored. This could be a specific shelf, room, or storage area within your archival facility.\n",
      "\n",
      "2. Create a unique identifier for the location, such as a shelf number or storage area code, to easily reference the Container's placement.\n",
      "\n",
      "3. Use a standardized system for recording the location information, such as a database or inventory management software, to ensure consistency and accuracy.\n",
      "\n",
      "4. Label the Container with its assigned location information, using clear and durable labeling materials to prevent confusion or misplacement.\n",
      "\n",
      "5. Update any relevant finding aids or catalog records to reflect the assigned location, making it easy for other archivists or researchers to locate the Container when needed.\n",
      "\n",
      "By following these steps, you can effectively assign location information to a Container as an Archivist, ensuring that it is properly stored and easily accessible for future use.  Providing the input query As a Data Publishing User, I want to be able to import data from a Google Spreadsheet, So that I do not have to convert data formats in order to use the data packager.\t\n",
      " Describing the input query As a Data Publishing User, I require the ability to import data directly from a Google Spreadsheet. This feature eliminates the need to convert data formats, streamlining the process of using the data packager and enabling seamless integration of data into the platform for publication and sharing.  Providing the input query As a Data Publishing User, I want to be able to import data from a Google Spreadsheet, So that I do not have to convert data formats in order to use the data packager.\t\n",
      " Describing the input query As a Data Publishing User, I require the ability to import data directly from a Google Spreadsheet. This feature eliminates the need to convert data formats, streamlining the process of using the data packager and enabling seamless integration of data into the platform for publication and sharing.  Providing the input query As a CONNECT user, I need bugs related to HIEM Notify transaction to be fixed and successfully validated to ensure/validate that HIEM service works in Rel 4.0.\t\n",
      " Describing the input query Certainly, here are short summary answers for all the queries:\n",
      "\n",
      "1. **Bug Fixes for HIEM Notify Transactions (CONNECT Release 4.0)**:\n",
      "   - Identify and prioritize bugs related to HIEM Notify transactions.\n",
      "   - Fix bugs, conduct testing, and validate fixes to ensure the correct functioning of the HIEM service in Release 4.0.\n",
      "\n",
      "By addressing these bugs, users can ensure the reliability and effectiveness of the HIEM service in CONNECT Release 4.0.  Providing the input query As a CONNECT user, I need bugs related to HIEM Notify transaction to be fixed and successfully validated to ensure/validate that HIEM service works in Rel 4.0.\t\n",
      " Describing the input query Certainly, here are short summary answers for all the queries:\n",
      "\n",
      "1. **Bug Fixes for HIEM Notify Transactions (CONNECT Release 4.0)**:\n",
      "   - Identify and prioritize bugs related to HIEM Notify transactions.\n",
      "   - Fix bugs, conduct testing, and validate fixes to ensure the correct functioning of the HIEM service in Release 4.0.\n",
      "\n",
      "By addressing these bugs, users can ensure the reliability and effectiveness of the HIEM service in CONNECT Release 4.0. \n"
     ]
    }
   ],
   "source": [
    "example_indices_full = [40, 80, 120]\n",
    "example_index_to_summarize = 200\n",
    "\n",
    "few_shot_prompt = make_prompt(example_indices_full, example_index_to_summarize)\n",
    "\n",
    "print(few_shot_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------\n",
      "Example  2\n",
      "---------------------------------------------------------------------------------------------------\n",
      "INPUT PROMPT:\n",
      "As a CONNECT tester, I would like to have a thorough set of regression tests for Document Retrieve, so that I can have proper test coverage\t\n",
      "\n",
      "ANSWER FROM CSV:\n",
      "To establish a comprehensive set of regression tests for Document Retrieve as a CONNECT tester:\n",
      "\n",
      "Analyze the Document Retrieve feature to understand its functionalities, inputs, and outputs.\n",
      "Collaborate with stakeholders to identify use cases, requirements, and expected behaviors.\n",
      "Develop a test plan that covers various scenarios, including:\n",
      "Retrieving documents by different criteria (e.g., patient ID, document ID, document type)\n",
      "Testing document retrieval in different formats (e.g., PDF, XML)\n",
      "Validating document retrieval responses against expected content and metadata\n",
      "Testing error handling and boundary cases (e.g., invalid document IDs, timeouts)\n",
      "Implement automation where feasible to streamline execution and improve efficiency.\n",
      "Execute the regression test suite regularly during the development lifecycle and before each release to ensure Document Retrieve functionality remains intact.\n",
      "Document test results, including any issues encountered during regression testing, for tracking and resolution.\n",
      "Continuously update and expand the regression test suite as new features are added or existing functionality evolves.\n",
      "Collaborate closely with developers and other team members to address any identified issues and ensure the quality of Document Retrieve functionality.\n",
      "\n",
      "MODEL GENERATION - WITH FEW SHOT LEARNING:\n",
      "providing the input query as an archivist, i want to assign location information to a container. describing the input query to assign location information to a container as an archivist, you can follow these steps : 1. determine the physical location where the container will be stored. this could be a specific shelf, room, or storage area within your archival facility. 2. create a unique identifier for the location, such as a shelf number or storage area code, to easily reference the container's placement. 3. use a standardized system for recording the location information, such as a database or inventory management software, to ensure consistency and accuracy. 4. label the container with its assigned location information, using clear and durable labeling materials to prevent confusion or misplacement. 5. update any relevant finding aids or catalog records to reflect the assigned location, making it easy for other archivists or researchers to locate the container when needed. by following these steps, you can effectively assign location information to a container as an archivist, ensuring that it is properly stored and easily accessible for future use. providing the input query as an archivist, i want to assign location information to a container. describing the input query to assign location information to a container as an archivist, you can follow these steps : 1. determine the physical location where the container will be stored. this could be a specific shelf, room, or storage area within your archival facility. 2. create a unique identifier for the location, such as a shelf number or storage area code, to easily reference the container's placement. 3. use a standardized system for recording the location information, such as a database or inventory management software, to ensure consistency and accuracy. 4. label the container with its assigned location information, using clear and durable labeling materials to prevent confusion or misplacement. 5. update any relevant finding aids or catalog records to reflect the assigned location, making it easy for other archivists or researchers to locate the container when needed. by following these steps, you can effectively assign location information to a container as an archivist, ensuring that it is properly stored and easily accessible for future use. providing the input query as a data publishing user, i want to be able to import data from a google spreadsheet, so that i do not have to convert data formats in order to use the data packager. describing the input query as a data publishing user, i require the ability to import data directly from a google spreadsheet. this feature eliminates the need to convert data formats, streamlining the process of using the data packager and enabling seamless integration of data into the platform for publication and sharing. providing the input query as a data publishing user, i want to be able to import data from a google spreadsheet, so that i do not have to convert data formats in order to use the data packager. describing the input query as a data publishing user, i require the ability to import data directly from a google spreadsheet. this feature eliminates the need to convert data formats, streamlining the process of using the data packager and enabling seamless integration of data into the platform for publication and sharing. providing the input query as a connect user, i need bugs related to hiem notify transaction to be fixed and successfully validated to ensure / validate that hiem service works in rel 4. 0. describing the input query certainly, here are short summary answers for all the queries : 1. * * bug fixes for hiem notify transactions ( connect release 4. 0 ) * * : - identify and prioritize bugs related to hiem notify transactions. - fix bugs, conduct testing, and validate fixes to ensure the correct functioning of the hiem service in release 4. 0. by addressing these bugs, users can ensure the reliability and effectiveness of the hiem service in connect release 4. 0. providing the input query as a connect user, i need bugs related to hiem notify transaction to be fixed and successfully validated to ensure / validate that hiem service works in rel 4. 0. describing the input query certainly, here are short summary answers for all the queries : 1. * * bug fixes for hiem notify transactions ( connect release 4. 0 ) * * : - identify and prioritize bugs related to hiem notify transactions. - fix bugs, conduct testing, and validate fixes to ensure the correct functioning of the hiem service in release 4. 0. by addressing these bugs, users can ensure the reliability and effectiveness of the hiem service in connect release 4. 0.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = dataset['train'][example_index_to_summarize]['result']\n",
    "\n",
    "inputs = tokenizer(few_shot_prompt, return_tensors='pt')\n",
    "\n",
    "decoded_input = tokenizer.decode(\n",
    "            inputs['input_ids'][0],\n",
    "            skip_special_tokens=True)\n",
    "\n",
    "print(dash_line)\n",
    "print('Example ', i + 1)\n",
    "print(dash_line)\n",
    "print(f'INPUT PROMPT:\\n{input_query}')\n",
    "    # print(dash_line)\n",
    "print(f'ANSWER FROM CSV:\\n{result}')\n",
    "print()\n",
    "    # print(dash_line)\n",
    "print(f'MODEL GENERATION - WITH FEW SHOT LEARNING:\\n{decoded_input}\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
